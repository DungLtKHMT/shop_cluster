{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6b555c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from cluster_library import RuleBasedCustomerClusterer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e975fb",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb29eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data\n",
    "print(\"Loading data...\")\n",
    "rules_df = pd.read_csv('../data/processed/rules_apriori_filtered.csv')\n",
    "cleaned_df = pd.read_csv('../data/processed/cleaned_uk_data.csv')\n",
    "clusters_ref = pd.read_csv('../data/processed/customer_clusters_from_rules.csv')\n",
    "\n",
    "print(f\"Total rules available: {len(rules_df)}\")\n",
    "print(f\"Total customers: {len(clusters_ref)}\")\n",
    "print(f\"Lift range: {rules_df['lift'].min():.2f} - {rules_df['lift'].max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895f6274",
   "metadata": {},
   "source": [
    "## 2. Initialize Clusterer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0ba2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize clusterer\n",
    "clusterer = RuleBasedCustomerClusterer(\n",
    "    df_clean=cleaned_df,\n",
    "    customer_col=\"CustomerID\",\n",
    "    invoice_col=\"InvoiceNo\",\n",
    "    item_col=\"Description\",\n",
    "    quantity_col=\"Quantity\"\n",
    ")\n",
    "\n",
    "# Build customer-item matrix (ch·ªâ c·∫ßn l√†m 1 l·∫ßn)\n",
    "print(\"Building customer-item matrix...\")\n",
    "clusterer.build_customer_item_matrix()\n",
    "print(f\"Customer-item matrix shape: {clusterer.customer_item_bool.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42e04e6",
   "metadata": {},
   "source": [
    "## 3. Compute RFM (s·∫Ω th√™m v√†o features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27431d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute RFM\n",
    "rfm_df = clusterer.compute_rfm()\n",
    "print(f\"RFM computed for {len(rfm_df)} customers\")\n",
    "print(rfm_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7322cc",
   "metadata": {},
   "source": [
    "## 4. Experiment v·ªõi c√°c gi√° tr·ªã Top-K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea80e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√°c gi√° tr·ªã Top-K ƒë·ªÉ th·ª≠ nghi·ªám\n",
    "TOP_K_VALUES = [50, 100, 200, 300, 500, 1000]\n",
    "K_CLUSTERS = 2  # S·ªë c·ª•m ƒë√£ ch·ªçn\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "results = []\n",
    "\n",
    "for top_k in TOP_K_VALUES:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Testing Top-K = {top_k}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Select top K rules by lift\n",
    "    rules_top_k = rules_df.nlargest(top_k, 'lift').reset_index(drop=True)\n",
    "    \n",
    "    # Ensure str columns exist\n",
    "    if 'antecedents_str' not in rules_top_k.columns:\n",
    "        rules_top_k['antecedents_str'] = rules_top_k['antecedents'].astype(str)\n",
    "    if 'consequents_str' not in rules_top_k.columns:\n",
    "        rules_top_k['consequents_str'] = rules_top_k['consequents'].astype(str)\n",
    "    \n",
    "    # Assign rules to clusterer\n",
    "    clusterer.rules_df_ = rules_top_k\n",
    "    \n",
    "    # Build rule feature matrix (weighted by lift)\n",
    "    X_rules = clusterer.build_rule_feature_matrix(\n",
    "        weighting='lift',\n",
    "        min_antecedent_len=1\n",
    "    )\n",
    "    \n",
    "    # Add RFM features\n",
    "    customers_list = clusterer.customers_\n",
    "    rfm_subset = rfm_df[rfm_df['CustomerID'].isin(customers_list)].set_index('CustomerID')\n",
    "    rfm_subset = rfm_subset.reindex(customers_list)\n",
    "    \n",
    "    # Scale RFM\n",
    "    scaler = StandardScaler()\n",
    "    rfm_scaled = scaler.fit_transform(rfm_subset[['Recency', 'Frequency', 'Monetary']])\n",
    "    \n",
    "    # Combine features\n",
    "    X_combined = np.hstack([X_rules, rfm_scaled])\n",
    "    \n",
    "    print(f\"Feature matrix shape: {X_combined.shape}\")\n",
    "    print(f\"Samples/Features ratio: {X_combined.shape[0]/X_combined.shape[1]:.2f}\")\n",
    "    \n",
    "    # Run K-Means\n",
    "    kmeans = KMeans(n_clusters=K_CLUSTERS, random_state=RANDOM_STATE, n_init=10)\n",
    "    labels = kmeans.fit_predict(X_combined)\n",
    "    \n",
    "    # Calculate Silhouette Score\n",
    "    sil_score = silhouette_score(X_combined, labels)\n",
    "    \n",
    "    # Analyze lift range\n",
    "    lift_min = rules_top_k['lift'].min()\n",
    "    lift_max = rules_top_k['lift'].max()\n",
    "    lift_mean = rules_top_k['lift'].mean()\n",
    "    \n",
    "    # Count cluster sizes\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    cluster_dist = dict(zip(unique, counts))\n",
    "    \n",
    "    result = {\n",
    "        'top_k': top_k,\n",
    "        'n_features': X_combined.shape[1],\n",
    "        'samples_per_feature': X_combined.shape[0] / X_combined.shape[1],\n",
    "        'silhouette_score': sil_score,\n",
    "        'lift_min': lift_min,\n",
    "        'lift_max': lift_max,\n",
    "        'lift_mean': lift_mean,\n",
    "        'cluster_0_size': cluster_dist.get(0, 0),\n",
    "        'cluster_1_size': cluster_dist.get(1, 0)\n",
    "    }\n",
    "    \n",
    "    results.append(result)\n",
    "    \n",
    "    print(f\"Silhouette Score: {sil_score:.4f}\")\n",
    "    print(f\"Lift range: {lift_min:.2f} - {lift_max:.2f} (mean: {lift_mean:.2f})\")\n",
    "    print(f\"Cluster distribution: {cluster_dist}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY OF ALL EXPERIMENTS\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29403f1",
   "metadata": {},
   "source": [
    "## 5. Visualization: So s√°nh Silhouette Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdb5e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot 1: Silhouette Score vs Top-K\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(results_df['top_k'], results_df['silhouette_score'], \n",
    "         marker='o', linewidth=2, markersize=10, color='#0284c7')\n",
    "ax1.axvline(x=200, color='red', linestyle='--', linewidth=2, label='Top-K = 200 (Chosen)')\n",
    "ax1.axhline(y=results_df[results_df['top_k']==200]['silhouette_score'].values[0], \n",
    "            color='red', linestyle=':', alpha=0.5)\n",
    "ax1.set_xlabel('Top-K (Number of Rules)', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Silhouette Score', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Silhouette Score vs Top-K\\n(Higher is Better)', fontsize=14, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend(fontsize=10)\n",
    "\n",
    "# Annotate best score\n",
    "best_idx = results_df['silhouette_score'].idxmax()\n",
    "best_k = results_df.loc[best_idx, 'top_k']\n",
    "best_score = results_df.loc[best_idx, 'silhouette_score']\n",
    "ax1.annotate(f'Best: {best_k}\\nScore: {best_score:.4f}', \n",
    "             xy=(best_k, best_score), xytext=(best_k+100, best_score-0.05),\n",
    "             arrowprops=dict(arrowstyle='->', color='red', lw=2),\n",
    "             fontsize=11, fontweight='bold', color='red')\n",
    "\n",
    "# Plot 2: Samples per Feature\n",
    "ax2 = axes[0, 1]\n",
    "ax2.plot(results_df['top_k'], results_df['samples_per_feature'], \n",
    "         marker='s', linewidth=2, markersize=10, color='#10b981')\n",
    "ax2.axhline(y=10, color='orange', linestyle='--', linewidth=2, label='Min Threshold (10:1)')\n",
    "ax2.axvline(x=200, color='red', linestyle='--', linewidth=2, label='Top-K = 200')\n",
    "ax2.set_xlabel('Top-K (Number of Rules)', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Samples per Feature Ratio', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Curse of Dimensionality Check\\n(Should be > 10)', fontsize=14, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend(fontsize=10)\n",
    "\n",
    "# Plot 3: Mean Lift by Top-K\n",
    "ax3 = axes[1, 0]\n",
    "ax3.plot(results_df['top_k'], results_df['lift_mean'], \n",
    "         marker='^', linewidth=2, markersize=10, color='#8b5cf6')\n",
    "ax3.axvline(x=200, color='red', linestyle='--', linewidth=2, label='Top-K = 200')\n",
    "ax3.set_xlabel('Top-K (Number of Rules)', fontsize=12, fontweight='bold')\n",
    "ax3.set_ylabel('Mean Lift Value', fontsize=12, fontweight='bold')\n",
    "ax3.set_title('Mean Lift vs Top-K\\n(Higher means stronger rules)', fontsize=14, fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.legend(fontsize=10)\n",
    "\n",
    "# Plot 4: Feature Count\n",
    "ax4 = axes[1, 1]\n",
    "ax4.bar(results_df['top_k'].astype(str), results_df['n_features'], \n",
    "        color=['red' if k==200 else '#64748b' for k in results_df['top_k']], alpha=0.7)\n",
    "ax4.set_xlabel('Top-K (Number of Rules)', fontsize=12, fontweight='bold')\n",
    "ax4.set_ylabel('Total Features (Rules + RFM)', fontsize=12, fontweight='bold')\n",
    "ax4.set_title('Feature Dimensionality\\n(Red = Chosen value)', fontsize=14, fontweight='bold')\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/top_k_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Visualization saved to: ../data/processed/top_k_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37efbc68",
   "metadata": {},
   "source": [
    "## 6. Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2ee969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary with rankings\n",
    "summary = results_df.copy()\n",
    "summary['sil_rank'] = summary['silhouette_score'].rank(ascending=False).astype(int)\n",
    "summary['quality'] = summary['top_k'].apply(lambda x: \n",
    "    '‚≠ê BEST' if x == 200 else \n",
    "    '‚úÖ Good' if x in [100, 300] else \n",
    "    '‚ö†Ô∏è Too Small' if x < 100 else \n",
    "    '‚ùå Too Large')\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"FINAL COMPARISON TABLE\")\n",
    "print(\"=\"*100)\n",
    "print(summary[['top_k', 'silhouette_score', 'sil_rank', 'samples_per_feature', \n",
    "               'lift_mean', 'quality']].to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"RECOMMENDATION\")\n",
    "print(\"=\"*100)\n",
    "best_row = summary[summary['top_k'] == 200].iloc[0]\n",
    "print(f\"üéØ Ch·ªçn Top-K = 200 v√¨:\")\n",
    "print(f\"   1. Silhouette Score cao nh·∫•t: {best_row['silhouette_score']:.4f}\")\n",
    "print(f\"   2. Samples/Feature t·ªët: {best_row['samples_per_feature']:.2f} (> 10 threshold)\")\n",
    "print(f\"   3. Mean Lift: {best_row['lift_mean']:.2f} (ƒë·ªß m·∫°nh)\")\n",
    "print(f\"   4. C√¢n b·∫±ng gi·ªØa information (capture 80% patterns) v√† noise (ch·ªâ 10%)\")\n",
    "print(f\"   5. Kh√¥ng b·ªã curse of dimensionality nh∆∞ Top-K l·ªõn (500, 1000)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15cf9c7",
   "metadata": {},
   "source": [
    "## 7. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dd23b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to CSV\n",
    "results_df.to_csv('../data/processed/top_k_experiment_results.csv', index=False)\n",
    "print(\"‚úÖ Results exported to: ../data/processed/top_k_experiment_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
